{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images/image1.jpg\n",
      "Found 1 trees\n",
      "test_images/image2.jpg\n",
      "Found 807 trees\n",
      "test_images/image3.jpg\n",
      "Found 380 trees\n",
      "test_images/image4.jpg\n",
      "Found 7512 trees\n",
      "test_images/image5.jpg\n",
      "Found 1218 trees\n",
      "test_images/image6.jpg\n",
      "Found 7740 trees\n",
      "test_images/image7.jpg\n",
      "Found 1202 trees\n",
      "test_images/image8.jpg\n",
      "Found 1588 trees\n",
      "test_images/image9.jpg\n",
      "Found 1 trees\n",
      "test_images/image10.jpg\n",
      "Found 2623 trees\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# skimage import io, filters\n",
    "#from scipy import ndimage\n",
    "#import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "PATH_TO_TEST_IMAGES_DIR = 'test_images'\n",
    "PATH_TO_RESULT_IMAGES_DIR = 'temp'\n",
    "PATH_TO_CONTOUR_IMAGES_DIR = 'Contours'\n",
    "\n",
    "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image'+str(i)+'.jpg') for i in range(1, 11) ]\n",
    "\n",
    "i=1\n",
    "'''\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    " \n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    " \n",
    "    # return the edged image\n",
    "    return edged\n",
    "'''\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "        print(image_path)    \n",
    "        img = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        negative = cv2.bitwise_not(img)\n",
    "        ret, bw1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "        ret, bw2 = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
    "        str0=os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image'+str(1)+'.jpg')       \n",
    "        str1=os.path.join(PATH_TO_RESULT_IMAGES_DIR, 'gimage'+str(i)+'.jpg')\n",
    "        cv2.imwrite(str1, gray)\n",
    "        str2=os.path.join(PATH_TO_RESULT_IMAGES_DIR, 'bw1image'+str(i)+'.jpg')\n",
    "        cv2.imwrite(str2,bw1)\n",
    "        str5=os.path.join(PATH_TO_RESULT_IMAGES_DIR, 'bw2image'+str(i)+'.jpg')\n",
    "        cv2.imwrite(str2,bw2)\n",
    "        str3=os.path.join(PATH_TO_RESULT_IMAGES_DIR, 'nimage'+str(i)+'.jpg')\n",
    "        cv2.imwrite(str3,negative)\n",
    "    \n",
    "        \n",
    "        contours,hierarchy = cv2.findContours(image=bw2, mode=cv2.RETR_EXTERNAL,method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "        print(\"Found %d trees\"%len(contours))\n",
    "    \n",
    "        str4=os.path.join(PATH_TO_CONTOUR_IMAGES_DIR, 'contour'+str(i)+'.jpg')\n",
    "        c=cv2.drawContours(image = bw2, contours = contours, contourIdx = -1, color = (0, 255, 0), thickness = 1)\n",
    "        cv2.imshow(\"Contours\"+str(i)+\".jpg\",c)\n",
    "        cv2.waitKey(30)\n",
    "        '''\n",
    "        im = cv2.imread('contour1.jpg')\n",
    "        detector = cv2.SimpleBlobDetector()\n",
    " \n",
    "        # Detect blobs.\n",
    "        keypoints = detector.detect(im)\n",
    "\n",
    "        # Draw detected blobs as red circles.\n",
    "        # cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of the circle corresponds to the size of blob\n",
    "        im_with_keypoints = cv2.drawKeypoints(im, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "        # Show keypoints\n",
    "        cv2.imshow(\"Keypoints\", im_with_keypoints)\n",
    "        cv2.waitKey(120)\n",
    "        \n",
    "        \n",
    "        im = io.imread(c, as_grey=True)\n",
    "        val = filters.threshold_otsu(im)\n",
    "        drops = ndimage.binary_fill_holes(im < val)\n",
    "        plt.imshow(drops, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        def load_image_into_numpy_array(image):\n",
    "            (im_width, im_height) = image.size\n",
    "            return np.array(image.getdata()).reshape(\n",
    "              (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "        detection_graph = tf.Graph()\n",
    "        with detection_graph.as_default():\n",
    "            with tf.Session(graph=detection_graph) as sess:\n",
    "                image = Image.open(str0)\n",
    "                # the array based representation of the image will be used later in order to prepare the\n",
    "                # result image with boxes and labels on it.\n",
    "                image_np = load_image_into_numpy_array(image)\n",
    "                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "                image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "                # Each box represents a part of the image where a particular object was detected.\n",
    "                boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "                # Each score represent how level of confidence for each of the objects.\n",
    "                # Score is shown on the result image, together with the class label.\n",
    "                scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "                num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "                # Actual detection.\n",
    "                (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "                # Visualization of the results of a detection.\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                np.squeeze(boxes),\n",
    "                np.squeeze(classes).astype(np.int32),\n",
    "                np.squeeze(scores),\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=1)\n",
    "                plt.figure(figsize=IMAGE_SIZE)\n",
    "                plt.imshow(image_np)\n",
    "        \n",
    "        from skimage import measure\n",
    "        labels = measure.label(drops)\n",
    "        print(labels.max())\n",
    "        print('coverage is %f' %(drops.mean()))\n",
    "        #edges = auto_canny(contours)\n",
    "        edges = cv2.Canny(c, 100, 200)\n",
    "        cv2.waitKey(delay=5)\n",
    "        plt.imshow(edges)\n",
    "        #cv2.destroyAllWindows()\n",
    "        \n",
    "        '''\n",
    "        i+=1 \n",
    "        \n",
    "         \n",
    "\n",
    "#im2, contours, hierarchy = cv2.findContours(bw, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#for cnt in contours:\n",
    "    #cv2.drawContours(bw,[cnt],0,(0,0,255),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
